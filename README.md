# ğŸ­ AI Fabrika - Master Prompt v3.0

**Sigurna AI Fabrika sa ugraÄ‘enim bezbednosnim slojevima**

## ğŸ›¡ï¸ Bezbednosne Karakteristike

### 1. **Path Sanitizer** (FileManager)
- âœ… Blokira Directory Traversal napade
- âœ… OgraniÄava pristup samo na radni folder projekta
- âœ… Automatska validacija svih putanja

### 2. **Security Sentinel** (Code Scanner)
- âœ… Detektuje SQL Injection ranjivosti
- âœ… Detektuje XSS vektore
- âœ… Blokira nesigurno izvrÅ¡avanje koda (`eval`, `exec`)
- âœ… Detektuje opasne sistemske komande
- âœ… Proverava nesigurne biblioteke
- âœ… SpreÄava eskalaciju privilegija

### 3. **Secure Orchestrator**
- âœ… Automatska validacija pre upisa koda
- âœ… Retry mehanizam sa feedback loop-om
- âœ… Token tracking i optimizacija

## ğŸ“¦ Instalacija

```bash
# 1. Instaliraj zavisnosti
pip install -r requirements.txt

# 2. Kopiraj i konfiguriÅ¡i environment varijable
copy .env.example .env
# Edituj .env i dodaj svoj API key
```

## ğŸš€ Pokretanje

```bash
python main.py
```

## ğŸ“ Struktura Projekta

```
setup_factory.py/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py    # Secure Orchestrator - mozak sistema
â”‚   â””â”€â”€ sentinel.py         # Security Sentinel - skener koda
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ file_manager.py     # FileManager sa Path Sanitizer-om
â”œâ”€â”€ generated/              # Ovde se kreiraju generisani fajlovi
â”œâ”€â”€ main.py                 # CLI interfejs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ”’ Kako FunkcioniÅ¡e Bezbednost?

### Workflow:

1. **KorisniÄki zahtev** â†’ LLM generiÅ¡e kod
2. **Security Sentinel** â†’ Skenira kod na ranjivosti
3. **Ako je bezbedan** â†’ FileManager upisuje (sa Path Sanitizer proverom)
4. **Ako nije bezbedan** â†’ LLM dobija feedback i pokuÅ¡ava ponovo (max 3 puta)

### Primer Blokiranog Koda:

```python
# âŒ BLOKIRANO - Nesigurno izvrÅ¡avanje
user_input = input("Unesi komandu: ")
eval(user_input)  # CRITICAL: CODE_EXECUTION

# âŒ BLOKIRANO - SQL Injection
query = f"SELECT * FROM users WHERE id = {user_id}"  # CRITICAL: SQL_INJECTION

# âŒ BLOKIRANO - Directory Traversal
file_manager.safe_write("../../etc/passwd", "hack")  # SecurityError!
```

### Primer Bezbednog Koda:

```python
# âœ… ODOBRENO - Parametrizovani upit
cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))

# âœ… ODOBRENO - Validiran unos
sanitized_input = sanitize_input(user_input)

# âœ… ODOBRENO - Putanja unutar projekta
file_manager.safe_write("generated/utils.py", code)
```

## ğŸ“Š Primer Izlaza

```
ğŸ­ AI FABRIKA - Master Prompt v3.0
======================================================================
ğŸ“ Radni direktorijum: D:\setup_factory.py
ğŸ¤– LLM Model: gpt-4o-mini
ğŸ›¡ï¸  Bezbednosni sloj: AKTIVAN
======================================================================

ğŸ“ Zadatak: Kreiraj 'generated/utils.py'
ğŸ’­ Prompt: Kreiraj helper funkcije...

[Orchestrator] PokuÅ¡aj 1/3 - Generisanje koda...
[FileManager] âœ“ Fajl uspeÅ¡no kreiran: generated\utils.py
[Orchestrator] âœ“ Kod uspeÅ¡no generisan i upisan u generated/utils.py

----------------------------------------------------------------------
ğŸ“Š REZULTAT GENERISANJA
----------------------------------------------------------------------
Fajl: generated/utils.py
Status: âœ“ USPEÅ NO
PokuÅ¡aji: 1
Tokeni: 450
Poruka: Kod uspeÅ¡no generisan i upisan u generated/utils.py

âœ“ Security Health Check: PASSED
----------------------------------------------------------------------
```

## ğŸ¯ Primeri Upotrebe

### Primer 1: Kreiraj Bezbedni Helper Modul

```python
factory.create_file(
    prompt="Kreiraj utils.py sa funkcijama za validaciju email-a i sanitizaciju unosa",
    filename="generated/utils.py"
)
```

### Primer 2: Kreiraj Database Modul

```python
factory.create_file(
    prompt="Kreiraj database.py sa parametrizovanim SQL upitima",
    filename="generated/database.py"
)
```

## âš™ï¸ Konfiguracija

### Environment Varijable (.env)

```bash
OPENAI_API_KEY=sk-...
DEFAULT_LLM_MODEL=gpt-4o-mini
```

### PodrÅ¾ani Modeli (preko litellm)

- OpenAI: `gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo`
- Anthropic: `claude-3-5-sonnet-20241022`, `claude-3-opus-20240229`
- Google: `gemini/gemini-pro`
- I mnogi drugi...

## ğŸ§ª Testiranje Bezbednosti

```python
from core.sentinel import SecuritySentinel

sentinel = SecuritySentinel()

# Test nesigurnog koda
unsafe_code = """
user_input = input()
eval(user_input)
"""

is_safe, threats = sentinel.scan_code(unsafe_code)
print(sentinel.generate_report())
```

## ğŸ“ Napomene

- **Token Optimizacija**: Koristi temperature=0.3 za deterministiÄki kod
- **Retry Mehanizam**: Maksimalno 3 pokuÅ¡aja za generisanje bezbednog koda
- **Least Privilege**: Kod ne moÅ¾e koristiti `sudo`, `admin` ili opasne sistemske komande
- **Automatska Validacija**: Svaki generisani kod prolazi kroz Security Sentinel pre upisa

## ğŸ¤ Doprinos

Ova AI Fabrika je dizajnirana sa bezbednoÅ¡Ä‡u kao prioritetom. Ako pronaÄ‘eÅ¡ novu ranjivost ili imaÅ¡ ideju za poboljÅ¡anje, slobodno doprinesi!

## ğŸ“„ Licenca

MIT License - Slobodno koristi i modifikuj.

---

**Napravljeno sa â¤ï¸ i ğŸ›¡ï¸ bezbednoÅ¡Ä‡u na umu**
